spring.sleuth.sampler.percentage=1.0

eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka/
eureka.instance.statusPageUrlPath=/swagger-ui.html
eureka.instance.lease-expiration-duration-in-seconds=30
eureka.instance.lease-renewal-interval-in-seconds=10
eureka.instance.prefer-ip-address=true
eureka.instance.metadata-map.weight=11

management.security.enabled=false

security.basic.enabled=false

spring.datasource.type=com.alibaba.druid.pool.DruidDataSource
spring.datasource.driverClassName=org.postgresql.Driver
#Replace the postgres with hdsc_db for all components and apps, postgress db is only used for demo project.
spring.datasource.url=jdbc:postgresql://localhost:5432/schedule?serverTimezone=UTC
spring.datasource.username=root
spring.datasource.password=123456
spring.datasource.name=druid

# the connection pool are applied to all of the above data sources
spring.datasource.druid.initialSize=5
spring.datasource.druid.minIdle=5
spring.datasource.druid.maxActive=20
# Configure the time to get a connection waiting for timeout
spring.datasource.druid.maxWait=60000
# How long is the interval to be detected to detect the free connection, the unit is milliseconds
spring.datasource.druid.timeBetweenEvictionRunsMillis=60000
# The minimum survival time in the connection pool. Unit is milliseconds
spring.datasource.druid.minEvictableIdleTimeMillis=300000
spring.datasource.druid.validationQuery=SELECT 1
spring.datasource.druid.testWhileIdle=true
spring.datasource.druid.testOnBorrow=true
spring.datasource.druid.testOnReturn=false
# Open the PSCache, and specify the size of the PSCache on each connection
spring.datasource.druid.poolPreparedStatements=true
spring.datasource.druid.maxPoolPreparedStatementPerConnectionSize=20
#  filters, after the removal of the monitoring interface SQL can not be statistics,'wall'for firewalls
spring.datasource.druid.filters=monitor,wall,log4j
# Open the mergeSql function through the connectProperties property; slow SQL record
spring.datasource.druid.connectionProperties=druid.stat.slowSqlMillis=500
# Merging multiple DruidDataSource monitoring data
#spring.datasource.druid.useGlobalDataSourceStat=true

server.port=9115
server.servlet.context-path=/

spring.application.name=scheduler-admin
xxl.job.login.username=admin
xxl.job.login.password=123456

### xxl-job, access token
starnetwork.job.accessToken=sdfadf23423423asdf452325343fgsfdgs

### xxl-job, i18n (default empty as chinese, "en" as english)
xxl.job.i18n=

xxl.scheduler.instanceName=DefaultQuartzScheduler
xxl.scheduler.instanceId=AUTO
xxl.scheduler.rmi.export=false
xxl.scheduler.rmi.proxy=false
xxl.scheduler.wrapJobExecutionInUserTransaction=false
xxl.threadPool.class=org.quartz.simpl.SimpleThreadPool
xxl.threadPool.threadCount=15
xxl.threadPool.threadPriority=5
xxl.threadPool.threadsInheritContextClassLoaderOfInitializingThread=true
xxl.jobStore.misfireThreshold=60000
xxl.jobStore.maxMisfiresToHandleAtATime=1
xxl.jobStore.tablePrefix=DJS.XXL_JOB_QRTZ_
xxl.jobStore.class=org.quartz.impl.jdbcjobstore.JobStoreTX
#xxl.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.PostgreSQLDelegate
#org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.PostgreSQLDelegate
xxl.jobStore.isClustered=true
xxl.jobStore.clusterCheckinInterval=5000
